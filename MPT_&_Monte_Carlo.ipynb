{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zixAi0ThgZ4I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import optuna\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "selected_tickers = ['NVDA', 'AAPL', 'AMZN', 'META', 'GOOGL'] #based on Optuna scores and discretion\n",
        "\n",
        "def get_annualized_return(ticker, start_date, end_date):\n",
        "\n",
        "    data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
        "\n",
        "    if 'Adj Close' in data.columns:\n",
        "        prices = data['Adj Close']\n",
        "    else:\n",
        "        prices = data['Close']\n",
        "    returns = prices.pct_change().dropna()\n",
        "\n",
        "    annualized_return = float((returns.mean() * 252).iloc[0] if hasattr(returns.mean(), 'iloc') else returns.mean() * 252)\n",
        "    return annualized_return\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    lookback_years = trial.suggest_int(\"lookback_years\", 3, 10)\n",
        "\n",
        "    d\n",
        "    training_end = \"2021-12-31\"\n",
        "    training_start_year = 2021 - lookback_years + 1  # e.g., for a 5-year lookback, start in 2017\n",
        "    training_start = f\"{training_start_year}-01-01\"\n",
        "\n",
        "    # Validation period: the year 2022\n",
        "    validation_start = \"2022-01-01\"\n",
        "    validation_end = \"2022-12-31\"\n",
        "\n",
        "    errors = []\n",
        "    for ticker in selected_tickers:\n",
        "        try:\n",
        "\n",
        "            train_ret = get_annualized_return(ticker, training_start, training_end)\n",
        "\n",
        "            val_ret = get_annualized_return(ticker, validation_start, validation_end)\n",
        "\n",
        "            errors.append(abs(train_ret - val_ret))\n",
        "        except Exception as e:\n",
        "\n",
        "            continue\n",
        "\n",
        "    avg_error = np.mean(errors) if errors else np.inf\n",
        "    return avg_error\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=1000)\n",
        "\n",
        "print(\"Best lookback period (years):\", study.best_params[\"lookback_years\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_tickers = ['NVDA', 'AAPL', 'AMZN', 'META', 'GOOGL']\n",
        "start_date = \"2012-01-01\"\n",
        "end_date   = \"2022-01-01\"\n",
        "\n",
        "\n",
        "data = yf.download(selected_tickers, start=start_date, end=end_date, progress=False)\n",
        "if isinstance(data.columns, pd.MultiIndex):\n",
        "    if \"Adj Close\" in data.columns.get_level_values(0):\n",
        "        stock_prices = data[\"Adj Close\"]\n",
        "    else:\n",
        "        stock_prices = data[\"Close\"]\n",
        "else:\n",
        "    if \"Adj Close\" in data.columns:\n",
        "        stock_prices = data[\"Adj Close\"]\n",
        "    else:\n",
        "        stock_prices = data[\"Close\"]\n",
        "\n",
        "\n",
        "stock_returns = stock_prices.pct_change().dropna()\n",
        "\n",
        "\n",
        "ff = web.DataReader(\"F-F_Research_Data_Factors\", \"famafrench\", start=start_date, end=end_date)[0]\n",
        "\n",
        "example_index = ff.index[0]\n",
        "if '-' in str(example_index):\n",
        "    ff.index = pd.to_datetime(ff.index.astype(str), format=\"%Y-%m\")\n",
        "else:\n",
        "    ff.index = pd.to_datetime(ff.index.astype(str), format=\"%Y%m\")\n",
        "\n",
        "ff_daily = ff.resample('D').ffill()\n",
        "\n",
        "ff_daily = ff_daily.loc[ff_daily.index >= pd.to_datetime(start_date)]\n",
        "\n",
        "ff_daily.columns = ff_daily.columns.str.replace('-', '_')\n",
        "\n",
        "ff_daily[['Mkt_RF', 'SMB', 'HML', 'RF']] = ff_daily[['Mkt_RF', 'SMB', 'HML', 'RF']] / 100\n",
        "\n",
        "\n",
        "\n",
        "expected_returns = {}\n",
        "for ticker in selected_tickers:\n",
        "    df = pd.concat([stock_returns[ticker], ff_daily], axis=1).dropna()\n",
        "    df.columns = ['stock_return', 'Mkt_RF', 'SMB', 'HML', 'RF']\n",
        "    df['excess_return'] = df['stock_return'] - df['RF']\n",
        "\n",
        "    X = df[['Mkt_RF', 'SMB', 'HML']]\n",
        "    X = sm.add_constant(X)\n",
        "    y = df['excess_return']\n",
        "    model = sm.OLS(y, X).fit()\n",
        "\n",
        "\n",
        "    avg_factors = ff_daily[['Mkt_RF', 'SMB', 'HML']].mean()\n",
        "    expected_daily_excess = (model.params['const'] +\n",
        "                             model.params['Mkt_RF'] * avg_factors['Mkt_RF'] +\n",
        "                             model.params['SMB'] * avg_factors['SMB'] +\n",
        "                             model.params['HML'] * avg_factors['HML'])\n",
        "    annual_expected_excess = expected_daily_excess * 252\n",
        "    annual_rf = ff_daily['RF'].mean() * 252\n",
        "    expected_returns[ticker] = annual_rf + annual_expected_excess\n",
        "\n",
        "\n",
        "\n",
        "cov_matrix = stock_returns[selected_tickers].cov() * 252\n",
        "\n",
        "\n",
        "num_portfolios = 15000\n",
        "results = np.zeros((3, num_portfolios))\n",
        "weights_record = []\n",
        "multi_expected_returns = np.array([expected_returns[ticker] for ticker in selected_tickers])\n",
        "risk_free_rate_annual = ff_daily['RF'].mean() * 252\n",
        "\n",
        "n = len(selected_tickers)\n",
        "min_weight = 0.05\n",
        "\n",
        "for i in range(num_portfolios):\n",
        "\n",
        "    weights = min_weight + np.random.dirichlet(np.ones(n)) * (1 - n * min_weight)\n",
        "    weights_record.append(weights)\n",
        "\n",
        "    port_return = np.dot(weights, multi_expected_returns)\n",
        "    port_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
        "    sharpe_ratio = (port_return - risk_free_rate_annual) / port_vol\n",
        "\n",
        "    results[0, i] = port_return\n",
        "    results[1, i] = port_vol\n",
        "    results[2, i] = sharpe_ratio\n",
        "\n",
        "results_df = pd.DataFrame(results.T, columns=['Return', 'Volatility', 'Sharpe Ratio'])\n",
        "max_sharpe_idx = results_df['Sharpe Ratio'].idxmax()\n",
        "max_sharpe_portfolio = results_df.iloc[max_sharpe_idx]\n",
        "optimal_weights = weights_record[max_sharpe_idx]\n",
        "\n",
        "print(\"\\nOptimal Portfolio using Multifactor Expected Returns (MPT):\")\n",
        "print(max_sharpe_portfolio)\n",
        "optimal_weights_df = pd.DataFrame({'Ticker': selected_tickers, 'Weight (%)': optimal_weights*100})\n",
        "print(\"\\nOptimal Weights (each >= 5%):\")\n",
        "print(optimal_weights_df)"
      ],
      "metadata": {
        "id": "m6bx-mOGhQQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from plotnine import (\n",
        "    ggplot, aes, geom_point, geom_label, scale_color_gradientn,\n",
        "    labs, theme_minimal, theme, element_text, element_blank\n",
        ")\n",
        "\n",
        "optimal_df = pd.DataFrame({\n",
        "    'Volatility': [max_sharpe_portfolio['Volatility']],\n",
        "    'Return': [max_sharpe_portfolio['Return']],\n",
        "    'Sharpe Ratio': [max_sharpe_portfolio['Sharpe Ratio']]\n",
        "})\n",
        "\n",
        "vol_pct = 100 * max_sharpe_portfolio['Volatility']\n",
        "ret_pct = 100 * max_sharpe_portfolio['Return']\n",
        "sharpe_val = max_sharpe_portfolio['Sharpe Ratio']\n",
        "\n",
        "optimal_label = (f\"Vol: {vol_pct:.1f}%\\n\"\n",
        "                 f\"Ret: {ret_pct:.1f}%\\n\"\n",
        "                 f\"Sharpe: {sharpe_val:.2f}\")\n",
        "optimal_df['Label'] = optimal_label\n",
        "\n",
        "custom_colors = [\n",
        "    \"#0096c7\",\n",
        "    \"#0077b6\",\n",
        "    \"#023e8a\"\n",
        "]\n",
        "\n",
        "gg = (\n",
        "    ggplot(results_df, aes(x='Volatility', y='Return', color='Sharpe Ratio'))\n",
        "    + geom_point(size=2.5, alpha=0.7)\n",
        "    + geom_point(\n",
        "        mapping=aes(x='Volatility', y='Return'),\n",
        "        data=optimal_df,\n",
        "        shape='^',\n",
        "        color='black',\n",
        "        size=6\n",
        "    )\n",
        "    + geom_label(\n",
        "        mapping=aes(label='Label'),\n",
        "        data=optimal_df,\n",
        "        color='white',\n",
        "        fill='black',\n",
        "        size=10,\n",
        "        label_padding=0.25,\n",
        "        label_size=0,\n",
        "\n",
        "        nudge_x=0.015,\n",
        "        nudge_y=0.015\n",
        "    )\n",
        "    + scale_color_gradientn(colors=custom_colors)\n",
        "    + labs(\n",
        "        title=\"Efficient Frontier using Multifactor Expected Returns\",\n",
        "        x=\"Annualized Volatility\",\n",
        "        y=\"Annualized Return\",\n",
        "        color=\"Sharpe Ratio\"\n",
        "    )\n",
        "    + theme_minimal(base_size=12, base_family='sans')\n",
        "    + theme(\n",
        "        figure_size=(12, 6),\n",
        "        axis_title=element_text(size=14),\n",
        "        plot_title=element_text(size=16),\n",
        "        legend_position='right',\n",
        "        panel_grid_minor=element_blank()\n",
        "    )\n",
        ")\n",
        "\n",
        "gg\n"
      ],
      "metadata": {
        "id": "c4V-gdfJhzIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def block_bootstrap_daily_returns(returns_data, weights, days_to_simulate, block_size, num_simulations=1000):\n",
        "    T = len(returns_data)\n",
        "    returns_array = returns_data.values\n",
        "    n_stocks = len(weights)\n",
        "\n",
        "    daily_returns_all = np.zeros((num_simulations, days_to_simulate), dtype=np.float64)\n",
        "\n",
        "    for sim_idx in range(num_simulations):\n",
        "        path_daily_returns = []\n",
        "        num_blocks = days_to_simulate // block_size\n",
        "        leftover_days = days_to_simulate % block_size\n",
        "\n",
        "\n",
        "        for _ in range(num_blocks):\n",
        "            start_idx = np.random.randint(0, T - block_size)\n",
        "            block = returns_array[start_idx:start_idx+block_size, :]  )\n",
        "            for day_returns in block:\n",
        "                path_daily_returns.append(np.dot(weights, day_returns))\n",
        "\n",
        "\n",
        "        if leftover_days > 0:\n",
        "            start_idx = np.random.randint(0, T - leftover_days)\n",
        "            leftover_block = returns_array[start_idx:start_idx+leftover_days, :]\n",
        "            for day_returns in leftover_block:\n",
        "                path_daily_returns.append(np.dot(weights, day_returns))\n",
        "\n",
        "        daily_returns_all[sim_idx, :] = path_daily_returns\n",
        "\n",
        "    return daily_returns_all\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "\n",
        "    block_size = trial.suggest_int('block_size', 5, 60)\n",
        "\n",
        "\n",
        "    daily_returns_all = block_bootstrap_daily_returns(\n",
        "        returns_data=stock_returns[selected_tickers].dropna(),\n",
        "        weights=optimal_weights,\n",
        "        days_to_simulate=252,\n",
        "        block_size=block_size,\n",
        "        num_simulations=10000\n",
        "    )\n",
        "\n",
        "    n_sims = daily_returns_all.shape[0]\n",
        "    sharpe_ratios = np.zeros(n_sims)\n",
        "\n",
        "\n",
        "    daily_rf = 0.0125 / 252\n",
        "\n",
        "    for i in range(n_sims):\n",
        "        path = daily_returns_all[i, :]\n",
        "        mean_path = np.mean(path)\n",
        "        std_path = np.std(path)\n",
        "\n",
        "\n",
        "        excess_mean = mean_path - daily_rf\n",
        "\n",
        "        if std_path == 0:\n",
        "            sharpe_ratios[i] = -9999\n",
        "        else:\n",
        "\n",
        "            sharpe_ratios[i] = (excess_mean / std_path) * np.sqrt(252)\n",
        "\n",
        "    avg_sharpe = np.mean(sharpe_ratios)\n",
        "    return avg_sharpe\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=10000, n_jobs=-1)\n",
        "\n",
        "print(\"Best parameters:\", study.best_params)\n",
        "print(\"Best daily Sharpe (with 1.25% RF):\", study.best_value)\n"
      ],
      "metadata": {
        "id": "IPJG_nHTh0zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_block_size = study.best_params['block_size']\n",
        "final_daily_returns = block_bootstrap_daily_returns(\n",
        "    returns_data=stock_returns[selected_tickers].dropna(),\n",
        "    weights=optimal_weights,\n",
        "    days_to_simulate=252,\n",
        "    block_size=best_block_size,\n",
        "    num_simulations=10000\n",
        ")\n"
      ],
      "metadata": {
        "id": "i7SiaieXh3Vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from plotnine import (\n",
        "    ggplot, aes, geom_histogram, geom_label, labs,\n",
        "    theme_minimal, theme, element_text\n",
        ")\n",
        "\n",
        "\n",
        "final_annual_returns = (1 + final_daily_returns).prod(axis=1) - 1\n",
        "\n",
        "\n",
        "mean_ret = final_annual_returns.mean()\n",
        "std_ret  = final_annual_returns.std()\n",
        "excess_mean = mean_ret - 0.0125\n",
        "if std_ret != 0:\n",
        "    final_sharpe = (excess_mean / std_ret) * np.sqrt(252)\n",
        "else:\n",
        "    final_sharpe = 0\n",
        "\n",
        "pct_5  = np.percentile(final_annual_returns, 5)\n",
        "pct_95 = np.percentile(final_annual_returns, 95)\n",
        "\n",
        "\n",
        "df = pd.DataFrame({'Annual Return': final_annual_returns})\n",
        "\n",
        "annotation_text = (\n",
        "    f\"Mean Annual Return: {mean_ret*100:.2f}%\\n\"\n",
        "    f\"Annual Volatility: {std_ret*100:.2f}%\\n\"\n",
        "    f\"Sharpe Ratio (1.25% RF): {final_sharpe:.2f}\\n\"\n",
        "    f\"5th Percentile (VaR): {pct_5*100:.2f}%\\n\"\n",
        "    f\"95th Percentile: {pct_95*100:.2f}%\"\n",
        ")\n",
        "\n",
        "\n",
        "hist_gg = (\n",
        "    ggplot(df, aes(x='Annual Return'))\n",
        "    + geom_histogram(bins=50, fill='skyblue', color='black', alpha=0.7)\n",
        "    + geom_label(\n",
        "        inherit_aes=False,\n",
        "        x=1.0,\n",
        "        y=700,\n",
        "        label=annotation_text,\n",
        "        label_size=0,\n",
        "        size=10,\n",
        "        color='black',\n",
        "        fill='white'\n",
        "    )\n",
        "    + labs(\n",
        "        title=\"Distribution of Final Annual Returns\",\n",
        "        x=\"Annual Return\",\n",
        "        y=\"Frequency\"\n",
        "    )\n",
        "    + theme_minimal(base_size=12)\n",
        "    + theme(\n",
        "        figure_size=(10, 6),\n",
        "        plot_title=element_text(size=16, weight='bold'),\n",
        "        axis_title=element_text(size=14)\n",
        "    )\n",
        ")\n",
        "\n",
        "hist_gg\n"
      ],
      "metadata": {
        "id": "7I0WdIHdh5qc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}